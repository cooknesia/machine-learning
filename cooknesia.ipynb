{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqoBexiw4UHz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_excel(\"/content/data_recipe.xlsx\")\n",
        "df.drop(columns=['province_id'], inplace=True, errors='ignore')"
      ],
      "metadata": {
        "id": "LYQsXyo44hBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bersihkan teks bahan\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "df['cleaned_bahan'] = df['bahan_bahan'].apply(clean_text)"
      ],
      "metadata": {
        "id": "Ub8mwTuX5yYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['cleaned_bahan'])"
      ],
      "metadata": {
        "id": "d5IxKhMQ546P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode ID Resep sebagai label\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['food_id'])\n",
        "y_cat = to_categorical(y)"
      ],
      "metadata": {
        "id": "e4db1Yso7zTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y_cat, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uCvHuplX768V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arsitektur model TensorFlow\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_cat.shape[1], activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcTTWwpjDanx",
        "outputId": "e197cf36-6df6-4e7f-83da-3797df828c29"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 184ms/step - accuracy: 1.5206e-04 - loss: 9.7376 - val_accuracy: 0.0018 - val_loss: 9.8869\n",
            "Epoch 2/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 159ms/step - accuracy: 0.0010 - loss: 9.6732 - val_accuracy: 0.0018 - val_loss: 10.1812\n",
            "Epoch 3/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 159ms/step - accuracy: 0.0017 - loss: 9.5292 - val_accuracy: 0.0018 - val_loss: 10.5713\n",
            "Epoch 4/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 152ms/step - accuracy: 0.0020 - loss: 9.0293 - val_accuracy: 0.0018 - val_loss: 11.3660\n",
            "Epoch 5/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 153ms/step - accuracy: 0.0114 - loss: 7.9553 - val_accuracy: 0.0018 - val_loss: 12.4656\n",
            "Epoch 6/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 156ms/step - accuracy: 0.0544 - loss: 6.5304 - val_accuracy: 0.0018 - val_loss: 13.9002\n",
            "Epoch 7/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 158ms/step - accuracy: 0.1782 - loss: 4.9131 - val_accuracy: 0.0018 - val_loss: 15.3052\n",
            "Epoch 8/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 152ms/step - accuracy: 0.3411 - loss: 3.5443 - val_accuracy: 0.0018 - val_loss: 16.4916\n",
            "Epoch 9/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 157ms/step - accuracy: 0.4994 - loss: 2.5271 - val_accuracy: 0.0018 - val_loss: 17.7256\n",
            "Epoch 10/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 150ms/step - accuracy: 0.6115 - loss: 1.8464 - val_accuracy: 0.0018 - val_loss: 18.2606\n",
            "Epoch 11/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 157ms/step - accuracy: 0.6847 - loss: 1.4389 - val_accuracy: 0.0018 - val_loss: 18.9181\n",
            "Epoch 12/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 150ms/step - accuracy: 0.7419 - loss: 1.1266 - val_accuracy: 0.0018 - val_loss: 19.4225\n",
            "Epoch 13/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 153ms/step - accuracy: 0.7861 - loss: 0.9366 - val_accuracy: 0.0018 - val_loss: 19.8952\n",
            "Epoch 14/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 157ms/step - accuracy: 0.8105 - loss: 0.8250 - val_accuracy: 0.0018 - val_loss: 20.0863\n",
            "Epoch 15/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 154ms/step - accuracy: 0.8321 - loss: 0.6907 - val_accuracy: 0.0018 - val_loss: 20.2911\n",
            "Epoch 16/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 156ms/step - accuracy: 0.8586 - loss: 0.5782 - val_accuracy: 0.0018 - val_loss: 20.4859\n",
            "Epoch 17/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 157ms/step - accuracy: 0.8729 - loss: 0.5137 - val_accuracy: 0.0018 - val_loss: 20.5960\n",
            "Epoch 18/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 150ms/step - accuracy: 0.8808 - loss: 0.4875 - val_accuracy: 0.0018 - val_loss: 21.0164\n",
            "Epoch 19/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 156ms/step - accuracy: 0.8911 - loss: 0.4263 - val_accuracy: 0.0018 - val_loss: 21.2866\n",
            "Epoch 20/20\n",
            "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.9053 - loss: 0.3743 - val_accuracy: 0.0018 - val_loss: 21.2187\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a21b6338610>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_recipe_ids(user_input, top_k=5):\n",
        "    if not user_input or not isinstance(user_input, str):\n",
        "        return \"Input bahan tidak valid.\"\n",
        "\n",
        "    cleaned_input = clean_text(user_input)\n",
        "    user_vec = vectorizer.transform([cleaned_input])\n",
        "\n",
        "    # Cosine similarity\n",
        "    similarities = cosine_similarity(user_vec, X).flatten()\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    # Output ID resep dan similarity\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        resep_id = int(df.iloc[idx]['food_id'])\n",
        "        similarity_score = round(similarities[idx], 4)\n",
        "        results.append({\"food_id\": resep_id, \"Similarity\": similarity_score})\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "MZRESHJlN19i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Contoh Penggunaan ---\n",
        "user_input = \"nasi, telur\"\n",
        "rekomendasi = recommend_recipe_ids(user_input)\n",
        "\n",
        "print(\"Rekomendasi ID Resep:\")\n",
        "for r in rekomendasi:\n",
        "    print(r)"
      ],
      "metadata": {
        "id": "63bmbO9hN6vx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77184d2-647c-4b15-8704-a58e13813cbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rekomendasi ID Resep:\n",
            "{'food_id': 16698, 'Similarity': np.float64(0.6351)}\n",
            "{'food_id': 9440, 'Similarity': np.float64(0.6011)}\n",
            "{'food_id': 5205, 'Similarity': np.float64(0.5728)}\n",
            "{'food_id': 11686, 'Similarity': np.float64(0.5264)}\n",
            "{'food_id': 2380, 'Similarity': np.float64(0.5114)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 1. Simpan model Keras (TensorFlow)\n",
        "model.save(\"resep_model.h5\")\n",
        "\n",
        "# 2. Simpan TF-IDF Vectorizer\n",
        "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "\n",
        "# 3. Simpan Label Encoder\n",
        "joblib.dump(le, \"label_encoder.pkl\")\n",
        "\n",
        "print(\"✅ Model dan semua komponen berhasil disimpan.\")"
      ],
      "metadata": {
        "id": "wO0mdeROO5gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfed80d-5357-4dd1-e4a3-38dab98434fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model dan semua komponen berhasil disimpan.\n"
          ]
        }
      ]
    }
  ]
}